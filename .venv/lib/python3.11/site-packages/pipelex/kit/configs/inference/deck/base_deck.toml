####################################################################################################
# Pipelex Model Deck - Base Configuration
####################################################################################################
#
# This file defines model aliases and presets for:
# - LLMs (language models for text generation and structured output)
# - Image generation models (for creating images from text prompts)
# - Document extraction models (OCR and text extraction from PDFs/images)
#
# Documentation: https://docs.pipelex.com
# Support: https://go.pipelex.com/discord
#
####################################################################################################

####################################################################################################
# Aliases
####################################################################################################

[aliases]
base-claude = "claude-4.5-sonnet"
base-gpt = "gpt-4o"
base-gemini = "gemini-2.5-flash"
base-mistral = "mistral-medium"

best-gpt = "gpt-4o"
best-claude = "claude-4.1-opus"
best-gemini = "gemini-2.5-pro"
best-mistral = "mistral-medium"
best-grok = "grok-3"

cheap-gpt = "gpt-4o-mini"
cheap_llm_for_text = "gpt-4o-mini"
cheap_llm_for_object = "gpt-4o-mini"
cheap_llm_for_vision = "gemini-2.5-flash-lite"

base_llm_for_text = "gpt-4o-mini"
base_llm_for_object = "gpt-4o-mini"

smart_llm = [
    "claude-4.5-sonnet",
    "claude-4.1-opus",
    "claude-4-sonnet",
    "gemini-2.5-pro",
    "gpt-4o",
]
llm_for_large_codebase = ["gemini-2.5-pro", "claude-4.5-sonnet", "gpt-5"]

# Image generation aliases
base-img-gen = "flux-pro/v1.1"
best-img-gen = "flux-pro/v1.1-ultra"
fast-img-gen = "fast-lightning-sdxl"

####################################################################################################
# LLM Presets
####################################################################################################

[llm.presets]

####################################################################################################
# LLM Presets — General purpose

cheap_llm_for_text = { model = "cheap_llm_for_text", temperature = 0.5 }
cheap_llm_for_short_text = { model = "cheap_llm_for_text", temperature = 0.5, max_tokens = 50 }
cheap_llm_for_object = { model = "cheap_llm_for_object", temperature = 0.5 }
cheap_llm_to_structure = { model = "cheap_llm_for_object", temperature = 0.1 }

llm_for_testing_gen_text = { model = "base_llm_for_text", temperature = 0.5 }
llm_for_testing_gen_object = { model = "base_llm_for_object", temperature = 0.5 }
llm_for_testing_vision = { model = "cheap_llm_for_vision", temperature = 0.5 }
llm_for_testing_vision_structured = { model = "cheap-gpt", temperature = 0.5 }

####################################################################################################
# LLM Presets — Specific skills

# Cheap llm
llm_cheap = { model = "base-gemini", temperature = 0.1 }

# Generation skills
llm_for_factual_writing = { model = "base-gpt", temperature = 0.1 }
llm_for_creative_writing = { model = "base-gpt", temperature = 0.9 }
llm_to_write_questions = { model = "gpt-4o-mini", temperature = 0.3 }

# Reasoning skills
llm_for_complex_reasoning = { model = "base-claude", temperature = 1 }
llm_to_reason_on_diagram = { model = "base-claude", temperature = 0.5 }
llm_to_analyze_data = { model = "base-claude", temperature = 0.5 }

# Search and answer skills
llm_to_answer_easy_questions = { model = "gpt-4o-mini", temperature = 0.3 }
llm_to_answer_hard_questions = { model = "base-claude", temperature = 0.3 }
llm_to_retrieve = { model = "base-claude", temperature = 0.1 }
llm_for_enrichment = { model = "gpt-4o", temperature = 0.1 }
llm_to_enrich = { model = "base-claude", temperature = 0.1 }
llm_for_question_and_excerpt_reformulation = { model = "gpt-4o", temperature = 0.9 }

# Engineering skills
llm_to_engineer = { model = "smart_llm", temperature = 0.2 }
llm_to_write = { model = "base-gemini", temperature = 0.2 }
llm_to_pipelex = { model = "base-claude", temperature = 0.2 }
llm_to_code = { model = "base-claude", temperature = 0.1 }
llm_to_analyze_large_codebase = { model = "base-claude", temperature = 0.1 }

# Image skills
llm_for_basic_vision = { model = "gpt-4o-mini", temperature = 0.1 }
llm_to_write_img_gen_prompt = { model = "base-claude", temperature = 0.2 }
llm_to_describe_img = { model = "base-claude", temperature = 0.5 }
llm_for_visual_analysis = { model = "base-claude", temperature = 0.5 }
llm_for_visual_design = { model = "base-claude", temperature = 0.5 }
llm_to_design_fashion = { model = "base-claude", temperature = 0.7 }
llm_for_img_to_text = { model = "base-claude", temperature = 0.1 }

# Extraction skills
llm_to_extract_diagram = { model = "base-claude", temperature = 0.5 }
llm_to_extract_invoice = { model = "claude-4.5-sonnet", temperature = 0.1 }
llm_to_extract_invoice_from_scan = { model = "base-claude", temperature = 0.5 }
llm_to_extract_legal_terms = { model = "base-claude", temperature = 0.1 }
llm_to_extract_tables = { model = "base-claude", temperature = 0.1 }

####################################################################################################
# LLM Choices
####################################################################################################

[llm.choice_defaults]
for_text = "cheap_llm_for_text"
for_object = "cheap_llm_for_object"

####################################################################################################
# Extract Presets
####################################################################################################

[extract]
choice_default = "extract_text_from_visuals"

[extract.presets]
extract_text_from_visuals = { model = "mistral-ocr", max_nb_images = 100, image_min_size = 50 }
extract_text_from_pdf = { model = "pypdfium2-extract-text", max_nb_images = 100, image_min_size = 50 }

####################################################################################################
# Image Generation Presets
####################################################################################################

[img_gen]
choice_default = "gen_image_basic"

[img_gen.presets]


# General purpose
gen_image_basic = { model = "base-img-gen", quality = "medium", guidance_scale = 7.5, is_moderated = true, safety_tolerance = 3 }
gen_image_fast = { model = "fast-img-gen", nb_steps = 4, guidance_scale = 5.0, is_moderated = true, safety_tolerance = 3 }
gen_image_high_quality = { model = "best-img-gen", quality = "high", guidance_scale = 8.0, is_moderated = true, safety_tolerance = 3 }

# Specific skills
img_gen_for_art = { model = "best-img-gen", quality = "high", guidance_scale = 9.0, is_moderated = false, safety_tolerance = 5 }
img_gen_for_diagram = { model = "base-img-gen", quality = "medium", guidance_scale = 7.0, is_moderated = true, safety_tolerance = 2 }
img_gen_for_mockup = { model = "base-img-gen", quality = "medium", guidance_scale = 6.5, is_moderated = true, safety_tolerance = 3 }
img_gen_for_product = { model = "best-img-gen", quality = "high", guidance_scale = 8.5, is_moderated = true, safety_tolerance = 2 }
img_gen_for_testing = { model = "fast-img-gen", nb_steps = 4, guidance_scale = 4.0, is_moderated = true, safety_tolerance = 4 }
